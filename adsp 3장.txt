																					adsp 3장

요약변수 
원래의 데이터로부터 기본적인 통계 자료를 추출한 변수

파생 변수
목적을 갖고 조건을 만족하는 변수들을 새롭게 생성한 것을 의미

데이터 탐색

이상값 판단 
ESD
평균적으로 표준편차 3만큼 떨어진 값들을 이상값으로 인식하는 방법
사분위수
25%에 해당하는 값과 75%에 해당하는 값을 활용하여 이상치를 판단하는 방법

통계분석
표본추출 방법
1. 단순 랜덤 추출법
가장 쉽고 단순한 방법으로 N개의 모집단에서 n개의 데이터를 무작위로 추출하는 방법 대표성이 떨어짐
2. 계통 추출법
N개의 모집단에서 K개씩 n개의 구간으로 나눈다. 첫 구간에서 하나를 임의로 선택하고 K개씩 띄어서 표본을 추출
123 | 456 | 789 | 101112 | 구간을 나눈뒤  그 구간에서 하나씩 뽑는다 |258|
3. 집락 추출법
군집 추출법이라 하며, 데이터를 여러 집락으로 구분한 뒤, 단순 랜덤 추출법에 의하여 선택된 집락의 데이터를 표본으로 사용하는 방법이다. 각 집락은 서로 동질적이며, 집락 내 데이터는 서로 이질적이다 ex) 
1학년 1반 2학년 1반 3학년 1반끼리 묶음
4. 층화 추출법
집락을 나눈 뒤, 각 집락에서 원하는 개수의 데이터를 추출하여 추출된 데이터에 대하여 표본조사를 실시한다.
ex) 1학년은 1학년끼리, 2학년은 2학년끼리, 3학년은 3학년끼리 묶는다. 하지만 학년별로 인원이 다를 수 있기에 
비례 층화 추출법 불비례 층화 추출법으로 나눈다.

비례 층화 추출법
전체 데이터의 분포를 반영하여 각 군집별 데이터를 추출하는 ㅂ아법
ex) 인원 수의 비례하여 비율과 동일하게 뽑는 것
불비례 층화 추출법 
각 군집에서 원하는 데이터를 추출하는 방법으로 원하는 군집에서 원하는 표본의 개수를 추출한다. 
ex) 인원 수 상관없이 뽑는것
측정과 척도의 개념
명목척도 측정 대상이 어느 집단에 속하는지 나타내는 자료 예) 성별, 지역
서열척도 측정 대상이 명목척도이면서 서열 관계를 갖는 자료 예) 선호도, 신용도, 학년 
구간척도 양을 측정할 수 있으며 두 구간 사이에 의미가 있는 자료 예) 온도, 지수
비율척도 절대적 기준 0이 존재하여 사칙연산이 가능한 자료 예) 신장, 무게, 점수, 가격

기술통계
표본 자체의 속성이나 특징을 파악하는 데 중점을 두는 데이터 분석 통계
ex) 데이터의 최솟값, 최댓값 등이 기술 통계량
추리통계
수집한 데이터를 바탕으로 '추론 및 예측'하는 통계 기법
ex) 가설을 검증하거나 확률적인 가능성을 파악한다

기술통계 이후 추리통계를 한다

분산 = (편차)^2합의 평균
편차 = 평균과의 차이
표준편차 = 루트 분산

확률변수와 확률분포 그리고 확률함수

집중화 경향 측정에 사용되는 값들
평균(MEAN) 꼬리가 긴쪽 값
값 들의 무게 중심이 어디인지를 나타내는 값, 산술 평균
중앙값(MEDIAN) 평균과 최빈값의 중간
자료를 크기 순서대로 배열했을 때 중앙에 위치하게 되는 값
최빈값(MODE) 그래프 중 가장 꼭대기에 있는 값
어떤 값이 가장 많이 관찰되는지 나타낸 값

독립사건 
A의 발생이 B가 발생할 확률을 바꾸지 않는 사건
두 사건 A,B가 독립이면 P(B|A) = P(B)
배반사건
교집합이 없는 것 
종속사건
두 사건 A와 B에서 한 사건의 결과가 다른 사건에 영향을 주는 사건
(음주와 사고 사건)

조건부확률 
사건 B가 발생했다는 조건 아래서 사건 A가 발생할 조건부 확률
예) P(음주|사고)의 값은 =(음주사고) / (음주사고 + 비음주사고) = 0.07/0.13 = 0.54

확률분포
분포 = 일정한 범위 안에 흩어져 퍼져 있는 정도
이산형 확률분포
각 사건은 서로 독립이어야 함, 확률변수가 몇 개의 한정된 가능한 값을 가지는 분포
예) 이항분포, 베르누이분포, 기하분포, 포아송분포
연속형 확률분포
확률변수의 가능한 값이 무한 개이며 사실상 셀 수 없을 때
예) 정규분포, 지수분포, 연속균일분포, 카이제곱분포, F분포

이산형 확률분포
베르누이분포
실험 결과 두 가지 중의 하나로 나오는 시행의 결과를 0 또는 1 값으로 대응시키는 확률변수 X에 대해 아래 식을
만족하는 확률변수 X가 따르는 확률분포

이항분포 
서로 독립된 베르누이 시행을 N 회 반복할 때 성공한 횟수를 X라 하면, 성공한 X의 확률분포를 말함

기하분포
베르누이 시행에서 처음 성공까지 시도한 횟수
포아송분포
단위 시간이나 단위 공간에서 어떤 사건이 몇 번 발생할 것인지를 표현하는 분포

기댓값
이산적 확률변수 기댓값 시그마 
연속적 확률변수 기댓값 인테그랄

정규분포 
가우스분포라고도 하며, 수집된 자료의 분포를 근사하는데 자주 사용함
평균 0, 표준편차/분산 1인 정규 분포, N(0,1) 를 표준 정규분포, Z분포라고 함

T-분포
자유도가 N인 T분포는 표준정규분포와 마찬가지로 평균이 0이고 좌우 대칭인 종 모양의 그래프지만 정규
분포보다 두꺼운 꼬리를 갖는다

자유도가 커질수록 T분포는 표준정규분포에 가까워진다( 꼬리가 커진다)


표준정규분포 
일정한 형태의 분포를 가진다

카이제곱분포)=교차검정
자유도가 높을수록 표준정규분포 모양에 가까워진다
모평균과 모분산을 모르는 두 개 이상의 집단을 검정할 때 사용

F-분포
서로 독립인 두 카이제곱 분포를 따르는 확률변수를 각각의 자유도로 나누었을 때 서로의 비율 X는 자유도가 K1,K2인 F 분포를 따른다

F분포는 카이제곱 분포와 비례 관계이다

연속확률변수 
확률변수가 취할 수 있는 실수 값이 어떤 특정 구간 전체에 해당하여 그 수를 셀 수 없는 변수를 연속확률변수

등분산 검정
두 모집단에 대하여 분산이 같은지 다른지를 검정하기 위한 가설검정

기댓값
특정 사건이 시행되었을 때 확률변수 X가 취할 수 있는 값의 평균 값
 
분산이 커지면 퍼짐의 정도가 큼
분산이 작으면 뾰족해짐

첨도와 왜도
첨도 
뾰족함의 정도

왜도
확률분포의 비대칭 정도를 나타내는 측도
왜도값이 음수면 우측으로 치우쳐져 있음, 우측으로 최빈값이 많음
왜도값이 양수면 좌측으로 치우쳐져 있음, 좌측으로 최빈값이 많음

공분산
두 확률변수 X,Y의 상관 정도를 나타내는 값

상관계수
공분산의 문제를 해결한 값
상관계수는 0 이면 상관관계가 없다
상관계수가 1이면 강한 양의 상관관계 양의 일차함수
상관계수가 -1이면 강한 음의 상관관계 음의 일차함수

회귀분석 
회귀선으로 데이터들이 회귀하는 것
회귀결정계수 값을 알면 미래의 값을 예측할 수 있다
회귀분석을 통해서 회귀결정계수를 알면 예전 데이터를 통해서 회귀선을 그릴 수 있고 미래를 예측할 수 있다 
최적회귀방정식 = 회귀 최소값을 알면 구할 수 있다

추정과 가설검정
귀무가설
나는 0이다, 0으로 되돌아간다
대립가설
귀무가설을 대립하는 가설, 틀렸다는걸 증명하고 싶은 가정
유의수준
0.05 =5%
0.01 =1%
우연히 발생하지않는다=고의로 발생한 일이다
고의적이다는 통계학적으로 유의미하다라고 한다
대립가설을 채택하고 귀무가설을 기각한다= 인과관계가 존재한다

가설검정의 개념
통계적 가설검정은 모집단의 특성에 대한 주장 또는 가설을 세우고 표본에서 얻은 정보를 이용해 가설이 옳은지를 판정하는 과정

귀무가설
모집단이 어떠한 특징을 지닐 것으로 여겨지는 가설로서 일반적으로 차이가 없다
대립가설
연구를 통해 증명하고자 하는 새로운 아이디어 혹은 가설에 해당한다
제1종 오류
귀무가설이 사실인데 귀무가설이 틀렸다고 결정하는 오류
제2종 오류
귀무가설이 사실이 아님에도 불구하고 귀무가설이 옳다고 결정하는 오류

기각역
기각역은 귀무가설을 기각하게 될 검정통계량의 영역으로 귀무가설을 기각시키는 귀

유의수준
귀무가설이 참인데도 이를 잘못 기각하는 오류를 범할 확률의 최대 혀용 한계
1%,5%를 주로 사용하며 가설검정을 수행하는 환경에 맞게 조절
유의확률=알파값(a)
귀무가설을 지지하는 정도를 나타내는 확률
P-value(분석값)가 유의수준 a보다 작은 경우 귀무가설이 참임을 가정했을 때 이러한 결과가 나올 확률이 매우적다고 해석할 수 있다 따라서 귀무가설을 기각하고 대립가설을 채택한다

모수검정
등간척도,비율척도 = 숫자 데이터들,피어슨 상관계수
비모수검정
명목척도,서열척도 = 정규분포를 따르지도 않고 분석방법이 특별한 것,스피어만 순위상관계수

t분포 = t검정
t검정
하나의 모집단의 평균값을 특저값과 비교하는 경우 사용하는 통계적 분석 방법
귀무가설 -> 가설검증 -> 대립가설이 옳고그름 증명

유의수준 > p-value 귀무가설 기각 X
반대로 p-value 값이 더 크면 귀무가설 기각 가능

대응 표본 t-검정(paired t-test=쌍)
대응 표본 t-검정의 개념
동일한 대상에 대해 두 가지 관측치가 있는 경우 이를 비교하여 차이가 있는지 검정할 때 사용

아노바 = 분산분석
세 개 이상의 모집단이 있을 경우에 여러 집단 사이의 평균을 비교하는 검정 방법
귀무 가설은  항상 모든 집단 간 평균은 같다
1. 정규성 각 집단의 표본들은 정규분포를 따라야 한다
2. 등분산성 각 집단은 동일한 분산을 가져야 한다
3. 독립성 각 집단은 서로에게 영향을 주지 않는다

일원분산분석
셋 이상의 집단 간 평균을 비교하는 상황에서 하나의 집단에 속하는 독립변수와 종속변수

이원분산분석
독립변수의 수가 두개 이상일 때 사용

교차분석
범주형 자료 간의 관계를 알아보고자 할 때 사용되는 분석방법

적합도 검정
실험결과 얻어진 관측값이 예상값과 일치하는지 여부를 검정하는 방법

독립성 검정
모집단이 두 개의 변수에 의해 범주화됐을 때 그 두 변수들 사이의 관계가 독립적인지 아닌지 검정하는 것을 의미

변수들 사이의 관계가 독립적이라면 변수들 사이에 유의한 관계가 없다고 판단 독립적이지 않다면 유의한 관계가 있다고 판단

두 범주형 변수가 유의한 관계가 있다고 판단한다고 해서 두 범주형 변수 간에 상관관계가 강하다고 보지는 않는다. 상관관계의 강도를 말하기 위해서는 상관분석을 실시해 수치를 따져봐야 한다

동질성 검정
관측값들이 정해진 범주 내에서 서로 비슷하게 나타나고 있는지를 검정하는 것

중심극한정리
모집단의 분포와 상관없이 표본의 개수 n이 커질수록 표본평군의 분포는 정규분포에 가까워지는 현상
주의할 점은 표본 집단의 평균 자체가 모집단의 평균과 같아지지는 않는다
엄청나게 많은 표본의 평균값을 구했다고 해서 그것이 곧 모집단의 평균과 같다고 볼 수 없다
정규분포와 가까워진다는 것은 특정한 사건이 일어날 확률을 구할 수 있다

상관분석
두 변수 간의 선형적 관계각 존재하는지 알아보는 분석 방법
-1에 가까우면 강한 음의 상관관계 +1에 가까우면 강한 양의 상관관계, 0에 가까울수록 상관관계 X

피어슨 상관분석(선형정 상관관계)
모수적 방법의 하나로 두 변수가 모두 정규분포를 따른다는 가정이 필요
method = 'pearson'

스피어만 상관분석(비선형적 상관관계)
측정된 두 변수들이 서열척도일 때 사용하는 상관계수
스피어만 상관계수는 비모수적 방법으로 관측값의 순위에 대하여 상관계수를 계산하는 방법'
method = 'spearman'

회귀분석
하나 이상의 독립변수들이 종속변수에 얼마나 영향을 미치는지 추정하는 통계기법 (인과관계가 얼마나 미치는지)

독립변수와 종속변수 간에 인과관계가 있다는 말은 독립변수가 원인이 되어 종속변수에 영향을 미친다는 의미
독립변수는 원인변수 종속변수는 결과변수라고도 한다

독립변수가 하나이면 단순선형회귀분석, 독립변수가 2개 이상이면 다중선형회귀분석으로 분석할 수 있다

변수선택법 

회귀분석의 가정
선형성 독립변수와 종속변수가 선형적이어야한다

독립성 잔차와 독립변수의 값이 서로 독립이어야 한다 
만약 독립변수들 간에 상관성이 존재하는 경우 다중공산성이라 하며, 이를 제거하고 회귀분석을 수행해야 한다

등분산성 분산이 같다는 의미이며 다른 말로 잔차들이 고르게 분포하고 있다는 의미
잔차의 중심에서 분산이 같아야 한다는 의미다. 
등분산성을 만족하지 못하면 회귀선은 어떤 추세를 띠지 못하고 덩어리 모양을 하게 된다

정규성 잔차항이 정규분포 형태를 띠는 것을 정규성을 만족하도록 한다

회귀계수의 추정
회귀계수는 기울기 
기울기가 높다는 것은 원인을 가정했을 때 결과가 쌔게 오는 것

최소제곱법으로 회귀계수 추정
최소제곱법을 통해 파라미터를 추정하고 추정된 파라미터를 통해 추세선을 그려 값을 예측하는 것
이것이 회귀분석의 기본 알고리즘이다
최소제곱법이란 실제 관측치와 추세선에 의해 예측된 점 사이의 거리, 즉 오차를 제곱해 더한 값을 최소화하는 것

SSE(오차제곱합) = 모형이 설명하지 못하는 부분 = MSE
SSR(회귀제곱합) = 모형이 설명하는 부분 = MSR
SST(총제곱합) = 전체 설명이 필요 SST = SSE + SSR

R2(회귀계수) = SSR / SST

회귀모형의 통계적 유의성은 F-검정을 통해 확인한다
F검정은 분산의 차이를 확인할때 사용되는데 이 분산의 차이가 크다는것은 회귀모형에서 회귀계수가 크다는 의미

회귀분석은 F-검정과는 비례관계이다
F-통계량 즉 F값이 크다는 말은 회귀계수가 크고 가파르다는 말과 같으니 변수 간에 유의미한 인과 관계가 존재한다

F값이 크면 P값은 상대적으로 작아진다 P값은 회귀모형에서 0.05보다 작을 경우 유의미한 인과관계가 있다

회귀계수의 유의성은 T-검정을 통해 확인가능

회귀분석 결과를 보는 법
T-통계량 = 회귀계수 / 표준오차
3.9324 / 0.4155 = 9.464(T-통계량)

다중선형회귀분석

다중공선성
독립변수가 1개인 단순선형회귀분석에서는 문제가 되지 않지만 독립변수가 2개 이상인 다중선형회귀분석
에서는 다중공선성에 유의해야 한다
다중공선성이란 회귀분석에서 독립변수 간에 강한 상관관계가 나타내는 문제이다
다중공선성이 존재하면 회귀분석의 기본 가정인 독립성에 위배된다

다중공선성 문제 해결법
변수를 제거한다
변수의 차원을 축소한다
스크리 산점도를 사용해 주성분 개수를 선택한다
선형판별분석으로 차원을 축소한다
T-분포 확률적 임베딩으로 차원을 축소한다
특잇값 분해로 차원을 축소한다

회귀분석에서 변수 선택이 중요
벌점화 방식
AIC
BIC
멜로우 Cp

단계적 변수 선택법
전진선택법 기준 통계치에서 가장 많은 영향을 줄 것으로 판단되는 변수부터 하나씩 추가하면서 모형을 선택한다
후진제거법 독립변수를 모두 포함하여 가장 적은 영향을 주는 변수로부터 하나씩 제거하는 방법
단계별 방법 전진선택법과 후진 제거법을 보안환 방법

고급 회귀분석
과적합과 과소적합
과적합이란 모델이 학습 데이터를 과하게 학습하는 것을 의미
학습 데이터에 과적합되면 일반화 성능이 낮아져 이미 학습한 훈련용 데이터에 대한 성능은 높게 나오지만,
아직 학습하지 않은 일반 테스트 데이터에 대한 성능은 낮게 나온다

반대로 
과소적합이란 모델이 너무 단순해서 학습 데이터조차 제대로 예측하지 못하는 경우

정규화 선형회귀
과적합이 될경우 계수의 크기가 과도하게 증가한다(예측력이 지나치게 높아지는 경우) 
이를 방지하기 위해 계수의 크기를 제한하는 방법을 정규화 선형회귀라고 한다
릿지,라쏘,엘라스틱넷 회귀모형이 사용

일반화 선형회귀
범주형 자료이거나 정규성을 만족하지 못하는 경우가 있다

일반화 선형회귀의 종류
로지스틱 회귀
종속변수가 범주형 변수 또는 합격/불합격, 사망/생존 등 인경우로 의학연구에 많이 사용
예측 모델을 생성한다는 점에서 선형 회귀 분석 방법과 동일하다 하지만 독립변수에 의해
종속 변수의 범주로 분류한다는 측면은 분류 분석 방법으로 분류
포아송 회귀

더빈 왓슨 검정
오차항이 상관관계를 갖는 경우는 대부분의 경우 시계열 데이터의 경우다.

더빈 왓슨 검정
회귀분석에 있어서는 오차항이 서로 연관성이 없어야 한다
만약 자기 상관성이 있다면 회귀분석이 아니라 시계열 분석이나 다른 분석 방법을 수행해야 한다

회귀분석의 평가 지표
MAE 절댓값으로 absoulte 절대의
MSE 제곱 square 제곱
RMSE 제곱
MAPE 절댓값 100 X

다차원 척도법
그림 문제가 주로 나옴
수박 멜론 딸기는 비슷한 부류이다
사과와 아보카도는 나머지 과일과 다른 부류의 과일이다

주성분분석
여러 개의 변수 중 서로 상관성이 높은 변수들의 선형결합으로 새로운 변수를 만드는 것
데이터들의 변수를 요약하여 하나의 변수로만 데이터의 위치 정보를 나타내는 것이 주성분 분석의 목적
변수를 축소해야 원인이 줄어듬

주성분분석의 목적
변수를 축소하여 설명력을 높임
다중공선성 문제를 해결
군집분석 시 모형의 성능을 높일 수 있다

주성분분석 scree plot
수평이 유지되기 전 왼쪽을 선택

주성분분석 biplot
다차원 척도법 그림이랑 비슷

시계열 분석의 개념

시계열 자료의 자기상관성
시계열 자료를 분석하는데 정상성 조건이 필요하다
일정한 평균
일정한 분산
시차에만 의존하는 공분산

자기상관계수
시간의 흐름에 따라 "다음 변수"에 영향을 미치는 것

부분자기상관계수
두 시계열 확률변수 간에 "다른 시점"의 확률변수 영향력은 통제하고 상관관계만 보여준다

시계열 분석 기법
이동평균법 일정 기간별로 자료를 묶어 평균을 구하는 방법
지수평활법 최근 데이터일수록 큰 가중치를 부여하고, 오래된 데이터일수록 작은 비중을 부여하는 방식을 사용해 평균을 계산

시계열 모형
AR모형(PACF) 그림 문제 
가능한 후보 모형은 막대그래프가 지나치는 것
MA모형(ACF) 그림 문제
막대 모형이 마지막으로 지나치는 것

자기회귀누적이동평균 모형(ARIMA)

분해 시계열
추세요인,계절요인, 순환요인, 불규칙요인 등으로 구성하여 특정 요인만 분리해 분석하거나 제거하는 작업
시계열 분석의 예측력을 높이기 위해서이다.

데이터 마이닝이란
데이터 마이닝은 방대한 양의 데이터 속에서 숨겨진 규칙, 패턴 등을 찾아내어 예측하거나 의사결정에
활용하는 것을 목적으로 한다 인공지능이 발달함에 따라 컴퓨터가 스스로 학습하는 알고리즘인 머신러닝을
구현하기 위한 바탕이 된다

전체 모집단을 대상으로 하느냐(데이터 마이닝)  VS 표본 집단을 대상으로 하느냐(통계분석)

데이터 마이닝의 종류
지도학습
정답이 있는 애들

비지도학습
정답을 알려주지 않고 학습하는 것

지도학습과 비지도학습
지도학습
회귀 선형회괴분석,의사결정나무,SVR,신경망 모형,릿지,라쏘
분류 로지스틱 회귀분석,신경망 모형,의사결정나무,K-NN,앙상블모형,SVM,나이브 베이즈 분류

비지도학습
군집 K-means,SOM,DBSCAN,병합 군집, 계층 군집
연관  Apriori
차원 축소 PCA, LDA, SVD, MDS

분류분석 영화나 음악의 등급 분류, 신용등급평가와 같이 데이터가 어느 그룹에 속하는지 판별하고자 하는 분석
군집분석 여러 이질적인 데이터들 사이의 유사성을 측정하여 유사성이 높은 객체끼리 하나의 그룹으로 묶기 위한 분석 방법
연관분석 장바구니 분석으로 불리고 맥주를 사는 고객은 기저귀를 살 가능성이 높다와 같이 데이터의 연관성을 파악하는 분석 방법

데이터 마이닝의 프로세스
목적정의
데이터 준비
데이터 가공
데이터 마이닝 기법 적용
검증

모형 선정 플로 차트
차원 축소 YES 비지도학습- 차원축소
차원 축소 NO -> 종속여부 존재 여부 YES 지도학습 NO 비지도학습
 
데이터분할의 의미
분할하는 의미는 예측력을 높이기 위해서 이다

데이터마이닝
회귀분석의 과적합과 과소적합을 방지하기 위해서 데이터 분할을 한다
첫번째로 홀드아웃
두번째로 K-Fold 교차검증
세번째로 붓스트랩
네번째로 계층별 k-겹 교차 검증을 실시한다

분류분석
로지스틱 회귀분석의 알고리즘
1. 오즈  식은 성공/실패
2 로짓변환
3 시그모이드 함수

의사결정나무
트리구조를 가진다
자료를 학습하여 특정 분리 규칙을 찾아낸다(비지도 학습)
종속변수가 연속형인 회귀트리, 이산형인 분류트리

의사결정나무의 특징
장점
모델이 직관적이고 해석이 용이하다
데이터 정규화 및 단위 변환이 필요하지 않다
다른 기법에 비해 전처리 작업이 어렵지 않다
이산형 변수, 연속형 변수 모두에 적용 가능
데이터의 선형성, 정규성 드으이 가정이 불필요하다
이상값에 민감하지 않다

단점
독립변수들 사이의 중요도를 판단하기 쉽지않다
분류 경계선 근처의 자료에 대해 오차가 크다
과적합 발생 가능성이 높다

의사결정나무의 분석 과정
1성장

계산 문제
카이제곱 통계량 CHAID
지니 지수 CART
엔트로피 지수 C4.5

 지니 지수 계산문제
앞면 확률 3/4 뒷면 확률 1/4
1-(3/4)^2 -(1/4)^2 = 6/16 = 0.811
 
2 가지치기

3 타당성 평가

4 해석 및 예측

앙상블 분석
여러 개의 모형을 생성 및 조합하여 예측력이 높은 모형을 만드는 것

대표적인 방법은 배깅 부스팅 랜덤포레스트
배깅
부스팅
여러 개의 모형을 구축한다는 점에서 배깅과 유사하지만, 배깅은 각 분류기가 독립적인데 반해 부스팅은 독립적이지 않다
XGBoost, Light GBM
모델을 계속 수정해서 나가는 방법

랜덤 포레스트 무작위성을 주는 분석 기법

인공신경만 분석
장점
잡음에 민감하게 반응하지 않는다
비선형적인 문제를 분석하는 데 유용하다
패턴인식, 분류, 예측 등의 문제에 효과적이다
스스로 가중치를 학습하므로 다양하고 많은 데이터에 효과적이다

단점
모형이 복잡할 경우 학습에 오랜 시간이 소요된다
초기 가중치에 따라 전역해가 아닌 지역해로 수렴할 수 있다
추정한 가중치의 신뢰도가 낮다
결과에 대한 해석이 쉽지 않다
은닉층의 수와 은닉 노드의 수를 결정하기가 어렵다

인공신경망의 알고리즘
활성함수
Step 함수 0 또는 1을 반환하는 함수
Sigmod 함수 0과 1 사이의 값을 반환한다
Sign 함수 -1 또는 1을 반환하는 이진형 함수
tanh 함수 -1과 1 사이의 값을 출력한다
ReLU 함수 0중에서 큰 값을 반환한다
Softmax 함수

인경신경망의 계층 구조
은닉층

인공신경망 학습 (순전파 알고리즘 ->역전파 알고리즘)

인공신경망의 종류
단층 퍼셉트론
다층 퍼셉트론

인공신경망 구조
RNN 순환 신경망으로 입력층의 데이터는 은닉층을 통해 출력층으로 가지만 은닉츠으이 결괏값이 다음 입력
데이터가 입력될 때 자기 자신에게 영향을 주는 신경망
CNN 합성곱 신경망으로 이미지 분류 및 다중객체탐지에 뛰어난 성능을 보인다
GAN 생산적 적대 신경망으로, 최적의 결과를 얻을 수 있도록 유도하는 학습 페이스북의 딥 페이스

K-NN알고리즘
K-NN은 정답 라벨이 없는 새로운 데이터를 입력받았을 때 그 데이터로부터 가장 가까이에 있는 데이터의 정답 라벨을 확인하여 새로운 데이터의 정답 라벨을 결정한다
결국 K값을 어떻게 정하는지가 관건이다

분류 모형 성과 평가
오분류표, ROC커브, 이익도표, 향상도곡선
오분류표&평가지표
TP(TRUE POSITIVE) 예측한 값이 긍정이고 실제 값도 긍정인 경우
FP(FALSE POSITIVE) 예측한 값이 긍정이고 실제 값도 부정인 경우
TN(TRUE NEGATIVE) 예측한 값이 부정이고 실제 값도 부정인 경우
FN(FALSE NEGATIVE) 예측한 값이 부정이고 실제 값도 긍정인 경우

정분류율
다 더한거 분의 TP + TN
오분류율
다 더한거 분의 FP + FN
정밀도 예측 TRUE 중 올바르게 TRUE 를 찾아낸 비율
TP + FP 분의 TP
민감도
특이도 실제 FALSE 중 올바르게 FALSE를 찾아낸 비율
TN + FP 분의 TN
민감도 실제 TRUE 중 올바르게 TRUE를 찾아낸 비율
TP + FN 분의 TP

F1 Score
민감도 + 정밀도 분의 2 x 민감도 x 정밀도

ROC커브 분류분석 모형의 평가를 쉽게 비교할 수 있도록 시각화한 그래프
면적이 클수록 평가성능이 좋다

이익도표
0.5에서 컷오프하며 1.0이 가장 높은 기준

향상도 곡선
좋은 모델일수록 급격히 감소한다

군집분석
군집으로 묶고 다변량 분석을 활용하여 군집에 대한 특징을 파악하는 기법

변수가 
덴드로그램 가로로 그었을 때 교차하는 개수가 군집 개수

비계층적 군집분석
K-MEANS 군집

자기조직화지도 SOM
코호넨 맵이라고 불리며, 인공신경망 기반 차원 축소와 군집화를 동시에 수행할 수 있는 알고리즘

연관분석
지지도
전체 분의 A교집합B
 
신뢰도
A분의 지지도
향상도
B분의 신뢰도



치킨->콜라
지지도  400/1000 0.4
신뢰도 0.4/0.6
향상도 0ㄹㅇㄹㅇ /0.7
















































































